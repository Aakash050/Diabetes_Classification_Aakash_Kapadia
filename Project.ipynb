{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports - Update as project complexity increases\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and looking at different aspects of data\n",
    "data_path = Path(\"data\") / \"diabetes.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "# Show top rows\n",
    "df.head()\n",
    "#We start to see strange values, it shouldn't be possible to have 0 skin thickness or 0 insulin. \n",
    "#Further investigation on these \"false 0's\" is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cleaning pipeline instead of inline code, allows for project modularity. Keep in mind this is only going to be used for EDA and data visualization, as I want to prevent potential data leakages. \n",
    "\n",
    "def cleaning_diabetes_data_for_eda(df):\n",
    "    df = df.copy()\n",
    "    zero_rows = {}\n",
    "    columns_to_clean = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "\n",
    "    for col in columns_to_clean:\n",
    "        #Chose to use median\n",
    "        false_zero_indices = df.index[df[col] == 0].tolist()\n",
    "        if false_zero_indices:\n",
    "            zero_rows[col] = false_zero_indices\n",
    "    print(\"False zeroes detected in the following columns:\")\n",
    "    for col, indices in zero_rows.items():\n",
    "        print (f\"-> Column '{col}' : Observations {indices}\")\n",
    "    df[columns_to_clean] = df[columns_to_clean].replace(0, np.nan)\n",
    "    \n",
    "    for col in columns_to_clean:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "clean_df = cleaning_diabetes_data_for_eda(df)\n",
    "clean_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Part 2: \n",
    "Now that we've cleaned our dataset, we start using EDA to understand what features are going to be important in our final machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.hist(figsize = (10,12), bins = 30, edgecolor = 'black') #Rule of thumb for bin specification\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#Most plots seem to be right skewed or normal, mainly due to presense of 0. For example:\n",
    "# A large number of women in our dataset have not been pregnant, or have only been pregnant once or twice. \n",
    "# Also, our median replacement creates large spikes at the median of our column for a lot of our predictors. It may be worth\n",
    "# Looking into dropping Nan values instead of replacing, will look into on a later step in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"]\n",
    "for col in predictors:\n",
    "    plt.figure(figsize = (6,4))\n",
    "    sns.kdeplot(data = clean_df, x = col, hue = \"Outcome\", fill = True)\n",
    "    plt.title(f\"Distribution of {col} by Outcome\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#Here we see that pregnancies, glucose, skin thickness, insulin, and diabetes pedigree function have very different PDFs per outcome.\n",
    "#Surprisingly, BMI and Blood pressure don't have extremely different PDFs per outcome in comparison to other predictors.\n",
    "#However, all variables could be reasonably assumed to be influential on diabetes. More investigation is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in predictors: \n",
    "    plt.figure(figsize = (6,4))\n",
    "    sns.boxplot(x = \"Outcome\", y = col, data = clean_df)\n",
    "    plt.title (f\"{col} by Diabetes Outcome\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "There are clear differences by outcome for BMI, Insulin, SkinThickness, BloodPressure, Glucose, and Pregnancies. Since we have relatively clear class seperation, a supervised model (labeled data) will work. No feature is completely dominant over the others, so a multivariable model will work best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Modeling (Keep in mind we are now back to using the original dataset, as cleaning before splitting can lead to data leakage):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0: Cleaning Transformer\n",
    "class ZerotoNan(BaseEstimator, TransformerMixin): \n",
    "    \"Replace false zeroes with Nans in specified columns\"\n",
    "    def __init__(self, columns): \n",
    "        self.columns = columns\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        cols = [c for c in self.columns if c in X.columns]\n",
    "        X[cols] = X[cols].replace(0, np.nan)\n",
    "        return X\n",
    "#Step 1: Initializing Models: \n",
    "models = { \"Logistic Regression\": LogisticRegression(random_state = 42, max_iter = 1000),\n",
    "          \"Random forest\": RandomForestClassifier(random_state = 42),\n",
    "          #Not linearly separable, so default kernel\n",
    "          \"Support Vector Machine\": SVC(probability = True, random_state = 42)\n",
    "         }\n",
    "#Step 2: Splitting data before cleaning, to prevent data leakage\n",
    "X = df.drop(\"Outcome\", axis = 1)\n",
    "y = df[\"Outcome\"].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "results = []\n",
    "fitted = {}\n",
    "\n",
    "#Step 3: Applying 0 transformer, then imputing using median, scaling values, and applying classifier\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline ([\n",
    "        (\"ZerotoNan\", ZerotoNan([\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"])),\n",
    "        ('imputer', SimpleImputer(strategy = 'median')),\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe, \"predict_proba\") else None\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "        \"ROC AUC Score\": roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan,\n",
    "    })\n",
    "    fitted[name] = pipe\n",
    "results_df = pd.DataFrame(results).sort_values(by = \"ROC AUC Score\", ascending = False).reset_index(drop = True)\n",
    "print(results_df)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Looking at our Accuracy, Precision, Recall, and F1 scores, we're at 60% - 80%. Next, I'm going to work on model tuning through hyperparameter tuning, and a confusion matrix and ROC curve for the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = results_df.loc[0, \"Model\"]\n",
    "best_model = fitted[best_name]\n",
    "print(f\"Best ROC AUC: {best_name}\")\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_proba_best = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best,zero_division = 0))\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "im = ax.imshow(cm, cmap=\"Blues\") \n",
    "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
    "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "ax.set_xticklabels([\"No Diabetes\",\"Diabetes\"]); ax.set_yticklabels([\"No Diabetes\",\"Diabetes\"])\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    ax.text(j, i, int(val), ha=\"center\", va=\"center\")\n",
    "from pathlib import Path\n",
    "Path(\"figures\").mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(\"figures/confusion_matrix.png\", dpi=150, bbox_inches=\"tight\") \n",
    "plt.show()\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(5, 4))\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test, ax = ax2)\n",
    "plt.title(f\"ROC Curve {best_name}\")\n",
    "fig2.savefig(\"figures/roc_curve.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline ([\n",
    "        (\"ZerotoNan\", ZerotoNan([\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"])),\n",
    "        ('imputer', SimpleImputer(strategy = 'median')),\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('clf', RandomForestClassifier(random_state = 42, class_weight = \"balanced\"))\n",
    "    ])\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\": randint(100,600),\n",
    "    \"clf__max_depth\": randint(2,20),\n",
    "    \"clf__min_samples_split\": randint(2,20),\n",
    "    \"clf__min_samples_leaf\": randint(1,10),\n",
    "    \"clf__max_features\": [\"sqrt\",\"log2\", None],\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs= -1,\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_best = rf_search.best_estimator_\n",
    "print(\"Best Random Forest Parameters:\", rf_search.best_params_)\n",
    "print(\"Best CV ROC AUC:\", rf_search.best_score_)\n",
    "\n",
    "y_pred_tuned = rf_best.predict(X_test)\n",
    "y_proba_tuned = rf_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "tuned_metrics = {\n",
    "    \"Model\": \"Random Forest (Tuned)\",\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_tuned),\n",
    "    \"Precision\": precision_score(y_test, y_pred_tuned, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, y_pred_tuned, zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred_tuned, zero_division=0),\n",
    "    \"ROC AUC Score\": roc_auc_score(y_test, y_proba_tuned),\n",
    "}\n",
    "compare_df = (pd.concat([results_df, pd.DataFrame([tuned_metrics])], ignore_index=True)\n",
    "                .sort_values(by=\"ROC AUC Score\", ascending=False)\n",
    "                .reset_index(drop=True))\n",
    "print(compare_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "Our Random Forest Tuned Model ended up being the best overall. In screening situations, recall is typically prioritized, as we want to capture as many true positives as possible. \n",
    "In terms of our test metrics, we have an accuracy of 74%, precision of 60%, recall of 74%, f1 score of 66%, and a ROC AUC of 82%.\n",
    "Also, since our CV best AUC is 84%, and our test AUC is 82%, we are relatively close, meaning we do not have overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
